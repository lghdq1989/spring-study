54.93.218.153

sudo yum install gcc

$ wget http://download.redis.io/redis-stable.tar.gz
$ tar xvzf redis-stable.tar.gz
$ cd redis-stable
$ make && make install

redis-cli -h my-cache.fafvgr.0001.usw2.cache.amazonaws.com -p 6379


Redis 常用命令
登录 redis-cli -p 5566 -a password
检查key是否存在 EXISTS key
搜索某关键字 KSYS *4
返回一个Key所影响的vsl的类型 TYPE key

1 String
设置一个键的值 SET key value
获取一个建的值 GET key
删除键对 DEL key
同时获取多个 mget key1 key2

2 Hash
设置一个hash HMSET key valueKey value --<key,<valueKey,value>>
获取hash所有key&value HGETALL key
获取hash所有key HKEYS key
获取hash所有keu的vslue HVALS key
获取hash内键值对的长度 HLEN key
给一个hash的某个键值对赋值 HSET key valueKey value
当hash中valueKey不存在时赋值 HSETNX key valueKey value

3 List
给list赋值 LPUSH listName value
按照索引取值 LINDEX listName 1



. Redis 设计规范 & 编码规范
转至元数据结尾
由 朱志敏创建, 最后修改于十月 12, 2020 转至元数据起始


Redis 设计规范


1.规范Key的格式

合适的Key，便于查看，统计，排错。

不推荐含义不清的Key和特别长的Key。例如："平台缩写"+":"+"项目名"+":"+"业务含义"。

例如：CRM:STUDENTS:USERINFO

":" 作为key分隔符，方便客户端工具作为目录分级

保证语义的前提下，控制 key 的长度，当 key 较多时，内存占用也不容忽视。

不要包含特殊字符。例如：包含空格、换行、单双引号以及其他转义字符

另外可参考以下几点说明：

有一套能区分业务归属的命名规范，key前缀是发生内存暴涨，性能问题时的分析定位问题的可行基础，Key的命名规范建议：

第1个字符小写定义数据类型：

string —>s,Hash—>h,Set—>s,Zset —>z,List —>l,Geo—>g

第2,3字符定义公开的业务分类：

第4-10个字符定义部门类的业务线细分

推荐的key中可使用符号.:#

不推荐使用的有：\ ? * {} [] ()

例：hCMappnode.product.detail:1312342

简洁性
保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如：
user:{uid}:friends:messages:{mid}简化为u:{uid}:fr:m:{mid}。

不要包含特殊字符
反例：包含空格、换行、单双引号以及其他转义字符

2. 冷热数据分离

冷热数据分离，不要将所有数据全部都放在Redis中

根据业务只将高频热数据存储到Redis中【QPS大于5000】，对于低频冷数据可以使用mysql等基于磁盘的存储方式。

不仅节省内存成本，而且数据量小操作时速度更快，效率更高。


3.选择适合的数据类型


例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡)

反例：

set user:1:name tom
set user:1:age 19
set user:1:favor football

正例：
hmset user:1 name tom age 19 favor football

4、value设计时，拒绝 bigkey。

string 类型控制在 10KB 以内，hash、list、set、zset 元素个数不要超过 5000

5、对于必须要存储的大文本数据一定要压缩后存储

6、线上Redis禁止使用Keys正则匹配操作

7、所有的key设置过期时间（比如可设置过期时间10天，特殊要求除外）

8、list的长度最大长度不超过1万，size不超过1G

9、string类型value长度不超过10M

10、不使用多个db,只使用db0,如果要区分业务线，在配置文件里定义各业务线使用的前缀





Redis 编码规范


需要了解的东西

在使用redis之前你首先要了解：①redis是单线程作业，所谓的并发是通过epoll实现的并发活跃连接；②redis与memcached相对优点明显，缺点不明显，因此还在犹豫的同学放心的选择redis吧；③在实际生产中因为客户端效率以及各节点通讯开销，redis几乎不可能达到官网上写的10w的qps；④在实际的使用过程中，redis最大的瓶颈一般是CPU，由于它是单线程作业所以很容易跑满一个逻辑CPU，可以使用redis代理或者是分布式方案来提升redis的CPU使用率。

redis 使用阈值建议

1.clients 连接数一般不超过2500
2.redis 单核cpu 使用率不超过50%
3.redis 每秒处理命令数不超过12000
4.redis 虚拟机网卡流量的出、入流量不超过800Mbps

redis 使用雷区

1.严格禁止 keys* 以及keys 匹配命令
2.禁止对数据结构、大范围操作和遍历的语句：lrange、hgetall、pipeline 之类的。lrange ,hgetall,hsetall 若key里面的filed比较多，每个field的value比较大时 ，性能都比较差
3.对于 sting 类型 value 值超过1M,list、hash、set、zset 元素个数超过5000，或者 value 值超过1M 的所有操作都必须谨慎，
强烈建议把以上bigkey进行拆分，或者把批量操作拆分成更小粒度的操作。



容量规划

在申请一个redis实例之前一定要对自己的容量需求有一个清楚的了解，因为redis在持久化过程中可能会使用额外的内存造成操作系统swapped，这将是一种毁灭性的故障现象，默认情况下我们会将一台服务器上所有redis的内存上限设置为：(物理内存-4G)*70%，当然这个70%不是固定的，会根据读写频率进行适当调整。
如果你不能准确计算你的redis实例所需内存容量，那就测试吧，按照实际的生产需求生成一定数量的数据，然后给出一个相对准确的数据。
注：redis在bgsave的时候cow使用的内存并非写多少数据用多少内存，redis一次申请的内存单位是页（默认是4k），因此在高吞吐又是随机性很高的写操作的背景下，cow使用一倍的内存不是不可能出现。

不同的业务数据要分开存储

不要将不相关的业务数据都放到一个Redis实例中，建议新业务申请新的单独实例。因为Redis为单线程处理，
独立存储会减少不同业务相互操作的影响，提高请求响应速度；同时也避免单个实例内存数据量膨胀过大，
在出现异常情况时可以更快恢复服务！简言之，不同业务数据要分开存储，尽可能的独立使用，
而不是多个业务共享同一redis实例。

节约内存

内存是redis的命根子，所以在使用过程中我们需要尽我们所能去节约有限的内存，需要注意的是Redis使用jemalloc作为内存分配器，内存的使用与分配并不是按照实际的key/field/value的字节数分配，而是按照一定的范围分配，详细请自行检索jemalloc size class categories相关信息。因此我们一般可以从这几个方面来节约内存的使用：

1. Value尽量都是整型，因为纯整型可以直接存储在指针位上，无需额外分配一个sds存储value
2. Redis以存储关系型数据为主，不允许存放长文本型数据(<=1K)
3. 使用Redis Set/ZSet/List时，需要衡量集合的大小(<=100w)，且需要考虑慢查的问题
4. 对于同一类对象，且数量不大可以考虑使用hset代替string，因为hset默认在小于512个fields时会使用压缩存储算法，
当然我们可以把hash-max-ziplist-entries设置为1000（超过1000时hset的CPU开销会加大），

比如：
set ob:1 123
set ob:2 234
可以改成：
hset ob 1 123
hset ob 2 234
       key的名称也要做到尽量的简单，比如我们举的例子中，key名称中所有的uid:是不是都可以去掉呢？在不影响应用的前提下，去掉可以节省大量内存，特别是存在大量string的时候。

内存淘汰策略

根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。
我们标准化部署的 redis 默认策略是allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。

其他策略如下：
allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。
allkeys-random：随机删除所有键，直到腾出足够空间为止。
volatile-random:随机删除过期键，直到腾出足够空间为止。
volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。
noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。
volatile-lru：即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。

合理利用管道操作


Redis提供一个pipeline的管道操作模式，将多个指令汇总到队列中批量执行，可以减少tcp交互产生的时间，一般情况下能够有10%~30%不等的性能提升。但是需要注意的是，pipeline与multi不同，无法保证请求之间的原子性，因此需要考虑使用场景。如果业务场景允许，这也是一个性能提升的点。

建议使用连接池

redis 应用客户端，需要在连接池设置连接超时，或者主动关闭连接，尤其对java 长连接类的应用，否则可能造成redis连接堆积，达到操作系统上限，导致无法接入新的连接。

标准使用方式，执行命令如下：

Jedis jedis = null;
try {
jedis = jedisPool.getResource();
//具体的命令
jedis.executeCommand()
} catch (Exception e) {
logger.error("op key {} error: " + e.getMessage(), key, e);
} finally {
//注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。
if (jedis != null)
jedis.close();
}

注意请求的时间复杂度


我们说过redis是单线程作业，因此一个复杂度高的请求对于一个高并发低延迟的系统是致命的，它会大大的拉低系统的整体吞吐，如果一定需要请把这些复杂度较高的请求（比如O(N)）放在一个slave server。

1. 案例一：某天某系统发现请求响应十分缓慢，查看php日志发现了大量的redis超时请求，再查看redis发现流量以及tcp请求均属于正常状态，但是redis使用的CPU出现100%现象。于是我们对该实例进行了请求采样，很快就发现了问题：该实例的平均QPS为69.24，大约26.54%的请求是keys请求，每次keys请求平均耗时约为13w微秒，key的总请求时间为该实例总请求时间的99.99%。把一个redis实例搞成69.24的QPS，这证明复杂度为O(N)的请求很快就能整跨一个redis实例、整垮一个系统。屏蔽掉keys请求之后，redis的qps直线上升，运营同学马上报来好消息，系统正常了系统正常了，玩家可以访问了。

2. 案例二：故事依然是那样的开头，故障排查解决。其中一个优化点就是：将复杂度为O(log(N)+M)的ZREVRANGE操作转换为list的O(1)操作，单单这点优化qps从5000上升到6500，约提升了30%。

减少不必要的请求


很多的代码框架都会产生大量的不必要请求，这个在MySQL使用上很严重，在redis上也经常出现。但是redis的使用通常是在一些高并发低延迟的场景中，因此不必要的请求会大大的拉低有效请求数。比如你的redis的吞吐大约是2w的qps，如果你的不必要请求大约占了40%，那意味着有效的用户请求才12000次/秒，如果干掉这部分不必要请求，那意味着有20000次/秒的有效用户请求，实际的业务吞吐量能提升67%。

1. 案例一：某业务系统的使用redis，根据开发同学反馈好像系统的吞吐量不高，于是我们对该redis实例进行了请求采样分析。采样100万次请求结果大概是这样的：该实例平均10554QPS，存在一次超过10000微秒的请求，平均响应时间为56.25微秒（Median ：56.25，75% ：114.0，90%：206.0，99%：561.0），其中“EXISTS”占37.34%请求。原来开发的同学在每次的请求之前都做了一次exists的请求，确认需要执行操作的key是否存在，其实大可不必，因为redis的所有请求对于不存在的key都会有输出返回，所以干掉所有的exists请求以后，在tps不变的情况下，该实例的有效用户请求能够提升：59.6%。

2. 案例二：同案例一，有一位同学喜欢在每次写数据之前先del一次，不管这个key存不存在（也许是延续使用MySQL开发的好习惯，先drop再create…）。其实大可不必啊，为啥呢？因为redis的写都是覆盖写，无需先删除一次。

关键业务需要有回源机制

对关键业务的redis，需要有数据库回源机制，当缓存失效或挂了后，需要到Mysql数据库查询来获取所需要的值，否则可能会影响业务。

备注：Key 使用方式和拆分的样例



场景：

    用户id: userId,

    用户微博数量：weiboCount

实现方法：有三种

(1) 使用Redis字符串数据结构, userId为key, weiboCount作为Value

(2) 使用Redis哈希结构，hashkey只有一个, key="allUserWeiboCount",field=userId,fieldValue= weiboCount

(3) 使用Redis哈希结构,  hashkey为多个, key=userId/100, field=userId%100, fieldValue= weiboCount。也就是每个hashKey存放100个hash-kv，field=userId%100



#获取userId=5003用户的微博数

(1) get 5003

(2) hget allUserWeiboCount 5003

(3) hget 50 3



内存占用量对比(100万用户 userId:1~1000000)